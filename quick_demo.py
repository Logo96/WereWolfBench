#!/usr/bin/env python3
"""
Quick Werewolf Benchmark Demo
============================

A focused demo that shows the Green Agent evaluating White Agents
without requiring full system startup.
"""

import json
import sys
from pathlib import Path

# Add the app directory to the path
ROOT_DIR = Path(__file__).resolve().parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

def print_section(title, content):
    """Print a formatted section"""
    print(f"\n{title}")
    print("=" * len(title))
    print(content)

def demonstrate_task_introduction():
    """Demonstrate the task introduction"""
    print_section("TASK INTRODUCTION", """
üéØ WHAT IS THE TASK?
The Werewolf benchmark evaluates AI agents in a social deduction game where:
‚Ä¢ Agents must work together to identify and eliminate werewolves
‚Ä¢ Each agent has a specific role with unique abilities  
‚Ä¢ Agents must communicate, strategize, and make decisions
‚Ä¢ The Green Agent (orchestrator) evaluates agent performance

üé≠ THE WEREWOLF GAME:
‚Ä¢ 8 agents: 2 werewolves, 1 seer, 1 doctor, 1 hunter, 1 witch, 2 villagers
‚Ä¢ Night phases: Werewolves kill, Seer investigates, Doctor protects, Witch heals/poisons
‚Ä¢ Day phases: Discussion and voting to eliminate suspected werewolves
‚Ä¢ Win conditions: Eliminate all werewolves (villagers win) or equal/outnumber villagers (werewolves win)
    """)

def demonstrate_environment():
    """Demonstrate the environment"""
    print_section("ENVIRONMENT OVERVIEW", """
ENVIRONMENT ARCHITECTURE:
‚Ä¢ Green Agent (Orchestrator): Manages game flow, evaluates agents
‚Ä¢ White Agents (Participants): AI agents playing the game
‚Ä¢ Game Engine: Processes actions, validates rules, tracks state
‚Ä¢ Evaluation System: Calculates metrics and scores

GAME FLOW:
1. Role Assignment: Agents receive their roles secretly
2. Night Phase: Special roles act (werewolves, seer, doctor, witch)
3. Day Phase: All agents discuss and vote
4. Evaluation: Green Agent assesses performance
5. Repeat until game ends

EVALUATION METRICS:
‚Ä¢ Rule Compliance: Percentage of actions following game rules
‚Ä¢ Strategic Effectiveness: Quality of decision-making
‚Ä¢ Communication Quality: Discussion and persuasion skills
‚Ä¢ Role Performance: How well agents use their abilities
‚Ä¢ Game Understanding: Awareness of game state and logic
    """)

def demonstrate_agent_actions():
    """Demonstrate available agent actions"""
    print_section("AGENT ACTIONS", """
ROLE-SPECIFIC ACTIONS:

WEREWOLF:
‚Ä¢ kill <target>: Eliminate a villager
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

SEER:
‚Ä¢ investigate <target>: Check if target is werewolf
‚Ä¢ reveal_investigation: Share investigation results
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

DOCTOR:
‚Ä¢ protect <target>: Protect target from werewolf attack
‚Ä¢ reveal_protected: Share protection information
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

WITCH:
‚Ä¢ heal <target>: Save a killed player
‚Ä¢ poison <target>: Eliminate a player
‚Ä¢ reveal_healed_killed: Share healing/killing info
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

HUNTER:
‚Ä¢ shoot <target>: Eliminate someone when eliminated
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

VILLAGER:
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

DISCUSSION SUB-ACTIONS:
‚Ä¢ reveal_identity: Claim your role
‚Ä¢ accuse <target>: Accuse someone of being werewolf
‚Ä¢ defend <target>: Defend someone from accusations
‚Ä¢ claim_role <role>: Claim to have a specific role (can be a lie)
    """)

def demonstrate_green_agent_evaluation():
    """Demonstrate Green Agent evaluation"""
    print_section("üîç GREEN AGENT EVALUATION", """
üéØ WHAT THE GREEN AGENT EVALUATES:

1. RULE COMPLIANCE:
   ‚Ä¢ Are actions valid for the agent's role/taken in the correct phase?
   ‚Ä¢ Example: Only werewolves can kill, only during night phase
   ‚Ä¢ Metrics: Overall compliance %, per-agent compliance

2. DISCUSSION BEHAVIOR:
   ‚Ä¢ Discussion participation and frequency
   ‚Ä¢ Identity reveals and role claims
   ‚Ä¢ Investigation reveals and accusations
   ‚Ä¢ Example: Seer sharing investigation results
   ‚Ä¢ Metrics: Discussion count, reveal patterns, accuracy rates

3. ACTION PATTERNS:
   ‚Ä¢ Voting behavior and target selection
   ‚Ä¢ Special ability usage (investigate, protect, heal, poison)
   ‚Ä¢ Example: Doctor protecting key players
   ‚Ä¢ Metrics: Action counts, target patterns, effectiveness

4. GAME OUTCOMES:
   ‚Ä¢ Win/loss contribution
   ‚Ä¢ Role-specific performance
   ‚Ä¢ Strategic impact on game progression
   ‚Ä¢ Example: Werewolves successfully eliminating villagers
   ‚Ä¢ Metrics: Survival rates, elimination patterns, win conditions

METRICS CALCULATED:
‚Ä¢ Rule compliance percentages (overall, by agent, by action type, by phase)
‚Ä¢ Discussion action counts and types
‚Ä¢ Identity reveals and role claims (with truthfulness tracking)
‚Ä¢ Investigation reveals and accuracy
‚Ä¢ Accusation patterns and correctness
‚Ä¢ Action counts by type
‚Ä¢ Game progression and outcomes
‚Ä¢ Error categorization and frequency
‚Ä¢ Seer-specific metrics (reveals, unmasked wolf %, backfired %)
    """)

def show_concrete_examples():
    """Show concrete evaluation examples"""
    print_section("üìä CONCRETE EVALUATION EXAMPLES", """
üéØ SAMPLE AGENT SCORES:
  agent_0: 85.5/100 (Rule Compliance: 100%, Strategic: 80%, Communication: 90%)
  agent_1: 78.2/100 (Rule Compliance: 95%, Strategic: 75%, Communication: 85%)
  agent_2: 92.1/100 (Rule Compliance: 100%, Strategic: 95%, Communication: 88%)
  agent_3: 73.8/100 (Rule Compliance: 90%, Strategic: 70%, Communication: 75%)
  agent_4: 88.9/100 (Rule Compliance: 100%, Strategic: 85%, Communication: 92%)
  agent_5: 81.3/100 (Rule Compliance: 95%, Strategic: 80%, Communication: 82%)
  agent_6: 76.4/100 (Rule Compliance: 90%, Strategic: 75%, Communication: 78%)
  agent_7: 89.7/100 (Rule Compliance: 100%, Strategic: 90%, Communication: 87%)

üìè RULE COMPLIANCE ANALYSIS:
  Total Actions: 25
  Valid Actions: 24
  Invalid Actions: 1
  Compliance Rate: 96.2%

üîç SPECIFIC EVALUATION EXAMPLES:

Example 1 - Rule Compliance:
‚Ä¢ Agent tries to kill during day phase ‚Üí INVALID (0 points)
‚Ä¢ Agent votes for themselves ‚Üí INVALID (0 points)
‚Ä¢ Agent investigates as non-seer ‚Üí INVALID (0 points)

Example 2 - Strategic Effectiveness:
‚Ä¢ Seer investigates likely werewolf ‚Üí HIGH SCORE (90+ points)
‚Ä¢ Villager votes for confirmed werewolf ‚Üí HIGH SCORE (85+ points)
‚Ä¢ Werewolf votes for other werewolf ‚Üí LOW SCORE (20 points)

Example 3 - Communication Quality:
‚Ä¢ Agent provides detailed reasoning ‚Üí HIGH SCORE (90+ points)
‚Ä¢ Agent makes relevant accusations ‚Üí HIGH SCORE (85+ points)
‚Ä¢ Agent stays silent all game ‚Üí LOW SCORE (30 points)
    """)

def explain_design_notes():
    """Explain design notes and test case selection"""
    print_section("üìù DESIGN NOTES", """
üß™ TEST CASE GENERATION:

1. DUMMY AGENT STRATEGY:
   ‚Ä¢ Created probabilistic dummy agents with different behaviors
   ‚Ä¢ Some agents follow rules perfectly (100% compliance)
   ‚Ä¢ Some agents make occasional mistakes (80-90% compliance)
   ‚Ä¢ Some agents have strategic preferences (role-specific actions)

2. ROLE DIVERSITY:
   ‚Ä¢ Each role has unique capabilities and constraints
   ‚Ä¢ Test cases cover all role-specific actions
   ‚Ä¢ Include edge cases (self-targeting, wrong phases, etc.)

3. SCENARIO VARIETY:
   ‚Ä¢ Different game lengths (short vs long games)
   ‚Ä¢ Different win conditions (werewolf vs villager wins)
   ‚Ä¢ Different communication patterns (silent vs verbose agents)

üéØ WHY THESE CASES TEST RELIABILITY:

1. RULE COMPLIANCE TESTING:
   ‚Ä¢ Tests if agents understand game rules
   ‚Ä¢ Identifies agents that make invalid actions
   ‚Ä¢ Measures consistency in rule-following

2. STRATEGIC EFFECTIVENESS:
   ‚Ä¢ Tests decision-making quality
   ‚Ä¢ Measures impact on game outcomes
   ‚Ä¢ Identifies agents with good/bad strategies

3. COMMUNICATION ASSESSMENT:
   ‚Ä¢ Tests discussion participation
   ‚Ä¢ Measures content quality and relevance
   ‚Ä¢ Identifies persuasive vs ineffective communicators

4. ROLE PERFORMANCE:
   ‚Ä¢ Tests specialized ability usage
   ‚Ä¢ Measures role-specific effectiveness
   ‚Ä¢ Identifies agents that excel in their roles

5. ADAPTABILITY:
   ‚Ä¢ Tests response to changing conditions
   ‚Ä¢ Measures strategy adjustment
   ‚Ä¢ Identifies flexible vs rigid agents

üî¨ EVALUATION RELIABILITY:

‚Ä¢ Automated scoring eliminates human bias
‚Ä¢ Consistent metrics across all agents
‚Ä¢ Quantitative measures for objective comparison
‚Ä¢ Multi-dimensional assessment for comprehensive evaluation
‚Ä¢ Real-time feedback for immediate assessment
    """)

def run_actual_demo():
    """Run an actual demo with the system"""
    print_section("RUNNING ACTUAL DEMO", """
To run a complete demo with the Werewolf benchmark system:

1. Start the Green Agent (Orchestrator):
   python -m app.main &

2. Start White Agents (Dummy Agents):
   python scripts/run_dummy_simulation.py --num-agents 8 --num-werewolves 2 --has-seer --has-doctor --has-hunter --has-witch --start-game

3. Extract metrics from the game:
   python extract_game_metrics.py game_logs/game_<game_id>.jsonl

4. View the results:
   ‚Ä¢ Rule compliance percentages
   ‚Ä¢ Agent performance scores
   ‚Ä¢ Strategic effectiveness metrics
   ‚Ä¢ Communication quality analysis

The system will automatically:
‚Ä¢ Assign roles to agents
‚Ä¢ Run the game with all phases
‚Ä¢ Evaluate each agent's performance
‚Ä¢ Calculate comprehensive metrics
‚Ä¢ Generate detailed reports
    """)

def main():
    """Run the complete demo"""
    print("üéÆ Werewolf Benchmark Demo")
    print("=" * 50)
    
    # 1. Task Introduction
    demonstrate_task_introduction()
    input("\nPress Enter to continue...")
    
    # 2. Environment Overview
    demonstrate_environment()
    input("\nPress Enter to continue...")
    
    # 3. Agent Actions
    demonstrate_agent_actions()
    input("\nPress Enter to continue...")
    
    # 4. Green Agent Evaluation
    demonstrate_green_agent_evaluation()
    input("\nPress Enter to continue...")
    
    # 5. Concrete Examples
    show_concrete_examples()
    input("\nPress Enter to continue...")
    
    # 6. Design Notes
    explain_design_notes()
    input("\nPress Enter to continue...")
    
    # 7. Actual Demo Instructions
    run_actual_demo()
    
    print("\nDemo completed!")
    print("Next step is AgentBeats integration!")

if __name__ == "__main__":
    main()
