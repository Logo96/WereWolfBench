#!/usr/bin/env python3
"""
Quick Werewolf Benchmark Demo
============================

A focused demo that shows the Green Agent evaluating White Agents
without requiring full system startup.
"""

import json
import sys
from pathlib import Path

# Add the app directory to the path
ROOT_DIR = Path(__file__).resolve().parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

def print_section(title, content):
    """Print a formatted section"""
    print(f"\n{title}")
    print("=" * len(title))
    print(content)

def demonstrate_task_introduction():
    """Demonstrate the task introduction"""
    print_section("TASK INTRODUCTION", """
üéØ WHAT IS THE TASK?
The Werewolf benchmark evaluates AI agents in a social deduction game where:
‚Ä¢ Agents must work together to identify and eliminate werewolves
‚Ä¢ Each agent has a specific role with unique abilities  
‚Ä¢ Agents must communicate, strategize, and make decisions
‚Ä¢ The Green Agent (orchestrator) evaluates agent performance

üé≠ THE WEREWOLF GAME:
‚Ä¢ 8 agents: 2 werewolves, 1 seer, 1 doctor, 1 hunter, 1 witch, 2 villagers
‚Ä¢ Night phases: Werewolves kill, Seer investigates, Doctor protects, Witch heals/poisons
‚Ä¢ Day phases: Discussion and voting to eliminate suspected werewolves
‚Ä¢ Win conditions: Eliminate all werewolves (villagers win) or equal/outnumber villagers (werewolves win)
    """)

def demonstrate_environment():
    """Demonstrate the environment"""
    print_section("ENVIRONMENT OVERVIEW", """
ENVIRONMENT ARCHITECTURE:
‚Ä¢ Green Agent (Orchestrator): Manages game flow, evaluates agents
‚Ä¢ White Agents (Participants): AI agents playing the game
‚Ä¢ Game Engine: Processes actions, validates rules, tracks state
‚Ä¢ Evaluation System: Calculates metrics and scores

GAME FLOW:
1. Role Assignment: Agents receive their roles secretly
2. Night Phase: Special roles act (werewolves, seer, doctor, witch)
3. Day Phase: All agents discuss and vote
4. Evaluation: Green Agent assesses performance
5. Repeat until game ends

EVALUATION METRICS:
‚Ä¢ Rule Compliance: Percentage of actions following game rules
‚Ä¢ Strategic Effectiveness: Quality of decision-making
‚Ä¢ Communication Quality: Discussion and persuasion skills
‚Ä¢ Role Performance: How well agents use their abilities
‚Ä¢ Game Understanding: Awareness of game state and logic
    """)

def demonstrate_agent_actions():
    """Demonstrate available agent actions"""
    print_section("AGENT ACTIONS", """
ROLE-SPECIFIC ACTIONS:

WEREWOLF:
‚Ä¢ kill <target>: Eliminate a villager
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

SEER:
‚Ä¢ investigate <target>: Check if target is werewolf
‚Ä¢ reveal_investigation: Share investigation results
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

DOCTOR:
‚Ä¢ protect <target>: Protect target from werewolf attack
‚Ä¢ reveal_protected: Share protection information
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

WITCH:
‚Ä¢ heal <target>: Save a killed player
‚Ä¢ poison <target>: Eliminate a player
‚Ä¢ reveal_healed_killed: Share healing/killing info
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

HUNTER:
‚Ä¢ shoot <target>: Eliminate someone when eliminated
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

VILLAGER:
‚Ä¢ discuss: Participate in day discussion
‚Ä¢ vote <target>: Vote for elimination

DISCUSSION SUB-ACTIONS:
‚Ä¢ reveal_identity: Claim your role
‚Ä¢ accuse <target>: Accuse someone of being werewolf
‚Ä¢ defend <target>: Defend someone from accusations
‚Ä¢ claim_role <role>: Claim to have a specific role (can be a lie)
    """)

def demonstrate_green_agent_evaluation():
    """Demonstrate Green Agent evaluation"""
    print_section("üîç GREEN AGENT EVALUATION", """
üéØ WHAT THE GREEN AGENT EVALUATES:

1. RULE COMPLIANCE:
   ‚Ä¢ Are actions valid for the agent's role/taken in the correct phase?
   ‚Ä¢ Example: Only werewolves can kill, only during night phase
   ‚Ä¢ Metrics: Overall compliance %, per-agent compliance

2. DISCUSSION BEHAVIOR:
   ‚Ä¢ Discussion participation and frequency
   ‚Ä¢ Identity reveals and role claims
   ‚Ä¢ Investigation reveals and accusations
   ‚Ä¢ Example: Seer sharing investigation results
   ‚Ä¢ Metrics: Discussion count, reveal patterns, accuracy rates

3. ACTION PATTERNS:
   ‚Ä¢ Voting behavior and target selection
   ‚Ä¢ Special ability usage (investigate, protect, heal, poison)
   ‚Ä¢ Example: Doctor protecting key players
   ‚Ä¢ Metrics: Action counts, target patterns, effectiveness

4. GAME OUTCOMES:
   ‚Ä¢ Win/loss contribution
   ‚Ä¢ Role-specific performance
   ‚Ä¢ Strategic impact on game progression
   ‚Ä¢ Example: Werewolves successfully eliminating villagers
   ‚Ä¢ Metrics: Survival rates, elimination patterns, win conditions

METRICS CALCULATED:
‚Ä¢ Rule compliance percentages (overall, by agent, by action type, by phase)
‚Ä¢ Discussion action counts and types
‚Ä¢ Identity reveals and role claims
‚Ä¢ Investigation reveals and accuracy
‚Ä¢ Accusation patterns and correctness
‚Ä¢ Action counts by type
‚Ä¢ Game progression and outcomes
‚Ä¢ Error categorization and frequency
‚Ä¢ Seer-specific metrics (reveals, unmasked wolf %, backfired %)
    """)


def demonstrate_dummy_agent_testing():
    """Demonstrate how dummy agents test the system implementation"""
    print_section("ü§ñ DUMMY AGENT TESTING SYSTEM", """
üß™ HOW DUMMY AGENTS TEST THE IMPLEMENTATION:

1. AUTOMATED TESTING FRAMEWORK:
   ‚Ä¢ Dummy agents simulate real AI agents with predictable behaviors
   ‚Ä¢ Each agent has role-specific strategies and decision patterns
   ‚Ä¢ 10% mistake rate intentionally introduced to test error handling
   ‚Ä¢ Probabilistic actions ensure varied test scenarios

2. ROLE-SPECIFIC BEHAVIOR TESTING:
   
   SEER AGENTS:
   ‚Ä¢ 60% chance to reveal investigation results
   ‚Ä¢ 30% chance to reveal identity as seer
   ‚Ä¢ 35% chance to make accusations
   ‚Ä¢ Tests investigation reveal patterns and accuracy

   DOCTOR AGENTS:
   ‚Ä¢ 50% chance to reveal protection actions
   ‚Ä¢ 30% chance to reveal identity as doctor
   ‚Ä¢ 35% chance to defend other players
   ‚Ä¢ Tests protection strategy and communication

   WITCH AGENTS:
   ‚Ä¢ 35% chance to reveal healing/killing actions
   ‚Ä¢ 30% chance to reveal identity as witch
   ‚Ä¢ 35% chance to make accusations
   ‚Ä¢ Tests healing/poisoning strategy and information sharing

   WEREWOLF AGENTS:
   ‚Ä¢ 60% chance to accuse villagers
   ‚Ä¢ 30% chance to defend teammates
   ‚Ä¢ 35% chance to claim fake roles
   ‚Ä¢ Tests deception strategies and team coordination

   VILLAGER AGENTS:
   ‚Ä¢ 40% chance to reveal identity
   ‚Ä¢ 30% chance to make accusations
   ‚Ä¢ 25% chance to defend others
   ‚Ä¢ Tests basic participation and reasoning

3. INVALID ACTION TESTING:
   ‚Ä¢ 10% mistake rate introduces rule violations
   ‚Ä¢ Tests system's ability to handle invalid actions
   ‚Ä¢ Examples: Voting for self, killing during day phase
   ‚Ä¢ Validates error logging and compliance tracking

4. SYSTEM COMPONENT TESTING:

   GAME ENGINE TESTING:
   ‚Ä¢ Action validation and rule enforcement
   ‚Ä¢ State transitions and phase management
   ‚Ä¢ Role-specific ability processing
   ‚Ä¢ Error handling and recovery

   EVALUATION SYSTEM TESTING:
   ‚Ä¢ Metrics calculation accuracy
   ‚Ä¢ Compliance tracking and reporting
   ‚Ä¢ Performance scoring algorithms
   ‚Ä¢ Multi-dimensional assessment

   LOGGING SYSTEM TESTING:
   ‚Ä¢ Event capture and serialization
   ‚Ä¢ Invalid action logging
   ‚Ä¢ Game completion tracking
   ‚Ä¢ JSONL format validation
    """)

def explain_design_notes():
    """Explain design notes and test case selection"""
    print_section("üìù DESIGN NOTES", """
üß™ TEST CASE GENERATION:

1. DUMMY AGENT STRATEGY:
   ‚Ä¢ Created probabilistic dummy agents with different behaviors
   ‚Ä¢ Some agents follow rules perfectly (100% compliance)
   ‚Ä¢ Some agents make occasional mistakes (80-90% compliance)
   ‚Ä¢ Some agents have strategic preferences (role-specific actions)

2. ROLE DIVERSITY:
   ‚Ä¢ Each role has unique capabilities and constraints
   ‚Ä¢ Test cases cover all role-specific actions
   ‚Ä¢ Include edge cases (self-targeting, wrong phases, etc.)

3. SCENARIO VARIETY:
   ‚Ä¢ Different game lengths (short vs long games)
   ‚Ä¢ Different win conditions (werewolf vs villager wins)
   ‚Ä¢ Different communication patterns (silent vs verbose agents)

üéØ WHY THESE CASES TEST RELIABILITY:

1. RULE COMPLIANCE TESTING:
   ‚Ä¢ Tests if agents understand game rules
   ‚Ä¢ Identifies agents that make invalid actions
   ‚Ä¢ Measures consistency in rule-following

2. STRATEGIC EFFECTIVENESS:
   ‚Ä¢ Tests decision-making quality
   ‚Ä¢ Measures impact on game outcomes
   ‚Ä¢ Identifies agents with good/bad strategies

3. COMMUNICATION ASSESSMENT:
   ‚Ä¢ Tests discussion participation
   ‚Ä¢ Measures content quality and relevance
   ‚Ä¢ Identifies persuasive vs ineffective communicators

4. ROLE PERFORMANCE:
   ‚Ä¢ Tests specialized ability usage
   ‚Ä¢ Measures role-specific effectiveness
   ‚Ä¢ Identifies agents that excel in their roles

5. ADAPTABILITY:
   ‚Ä¢ Tests response to changing conditions
   ‚Ä¢ Measures strategy adjustment
   ‚Ä¢ Identifies flexible vs rigid agents

üî¨ EVALUATION RELIABILITY:

‚Ä¢ Automated scoring eliminates human bias
‚Ä¢ Consistent metrics across all agents
‚Ä¢ Quantitative measures for objective comparison
‚Ä¢ Multi-dimensional assessment for comprehensive evaluation
‚Ä¢ Real-time feedback for immediate assessment
    """)

def run_actual_demo():
    """Run an actual demo with the system"""
    print_section("RUNNING ACTUAL DEMO", """
To run a complete demo with the Werewolf benchmark system:

1. Start the Green Agent (Orchestrator):
   python -m app.main &

2. Start White Agents (Dummy Agents):
   python scripts/run_dummy_simulation.py --num-agents 8 --num-werewolves 2 --has-hunter --has-witch --start-game

3. Parse metrics from the game:
   python parse_evaluation_metrics.py game_logs/game_<game_id>.jsonl

4. View the results:
   ‚Ä¢ Rule compliance percentages
   ‚Ä¢ Agent performance scores
   ‚Ä¢ Strategic effectiveness metrics
   ‚Ä¢ Communication quality analysis

The system will automatically:
‚Ä¢ Assign roles to agents
‚Ä¢ Run the game with all phases
‚Ä¢ Evaluate each agent's performance
‚Ä¢ Parse comprehensive metrics from game logs
‚Ä¢ Display detailed reports in a clean format
    """)

def main():
    """Run the complete demo"""
    print("üéÆ Werewolf Benchmark Demo")
    print("=" * 50)
    
    # 1. Task Introduction
    demonstrate_task_introduction()
    input("\nPress Enter to continue...")
    
    # 2. Environment Overview
    demonstrate_environment()
    input("\nPress Enter to continue...")
    
    # 3. Agent Actions
    demonstrate_agent_actions()
    input("\nPress Enter to continue...")
    
    # 4. Green Agent Evaluation
    demonstrate_green_agent_evaluation()
    input("\nPress Enter to continue...")
    
    # 5. Dummy Agent Testing
    demonstrate_dummy_agent_testing()
    input("\nPress Enter to continue...")
    
    # 6. Design Notes
    explain_design_notes()
    input("\nPress Enter to continue...")
    
    # 7. Actual Demo Instructions
    run_actual_demo()
    
    print("\nDemo completed!")
    print("Next step is AgentBeats integration!")

if __name__ == "__main__":
    main()
